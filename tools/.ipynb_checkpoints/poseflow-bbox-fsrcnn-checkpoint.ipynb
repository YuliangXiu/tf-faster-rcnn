{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.timer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-93aa04426429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_init_paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mim_detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.timer'"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import _init_paths\n",
    "import h5py\n",
    "import scipy.io as sio\n",
    "\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import skimage.io\n",
    "\n",
    "import utils\n",
    "from utils.timer import Timer\n",
    "from model.config import cfg\n",
    "from model.test import im_detect\n",
    "from model.nms_wrapper import nms\n",
    "from newnms.nms import  soft_nms\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, cv2\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nets.vgg16 import vgg16\n",
    "from nets.resnet_v1 import resnetv1\n",
    "\n",
    "\n",
    "CLASSES = ('__background__','human')\n",
    "#NETS = {'vgg16': ('vgg16_faster_rcnn_iter_70000.ckpt',),'res101': ('res101_faster_rcnn_iter_110000.ckpt',),'res152':('res152_faster_rcnn_iter_1190000.ckpt',)}\n",
    "NETS = {'vgg16': ('vgg16_faster_rcnn_iter_70000.ckpt',),'res101': ('res101_faster_rcnn_iter_110000.ckpt',),'res152':('res152.ckpt',)}\n",
    "DATASETS= {'pascal_voc': ('voc_2007_trainval',),'pascal_voc_0712': ('voc_2007_trainval+voc_2012_trainval',),'coco':('coco_2014_train+coco_2014_valminusminival',)}\n",
    "\n",
    "image_dir = \"/home/yuliang/data/MultiPerson_PoseTrack_v0.1/videos_align\"\n",
    "# image_dir = '/home/yuliang/data/mpii-video-pose/'\n",
    "# image_dir = '/home/yuliang/data/posetrack_data/posetrack_data'\n",
    "list_file = '/home/yuliang/code/PoseFlow/listfiles/bonn-small'\n",
    "# list_file = '/home/yuliang/code/PoseFlow/listfiles/mpii-video-pose'\n",
    "# list_file = '/home/yuliang/code/PoseFlow/listfiles/bonn-big'\n",
    "\n",
    "# test_list_file = os.path.join(list_file, 'test_list.txt')\n",
    "test_list_file = os.path.join(list_file, 'test_list_align.txt')\n",
    "# test_list_file = os.path.join(list_file, 'all_list.txt')\n",
    "\n",
    "\n",
    "lines = [line.rstrip('\\n') .rstrip('\\r') for line in open(test_list_file)]\n",
    "\n",
    "directory = '/home/yuliang/code/PoseFlow/dataset/generated_bbox/mask-rcnn-arg/bonn-small/'\n",
    "# directory = '/home/yuliang/code/PoseFlow/dataset/generated_bbox/mask-rcnn/mpii-video-pose/'\n",
    "# directory = '/home/yuliang/code/PoseFlow/dataset/generated_bbox/mask-rcnn/bonn-big/'\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "results = open(directory+\"test-bbox_images.txt\", 'w')\n",
    "score_file = open(directory+\"score.txt\",'w')\n",
    "index_file = open(directory+\"index.txt\",'w')\n",
    "\n",
    "FileLength = len(lines)\n",
    "\n",
    "\n",
    "num_boxes=0\n",
    "\n",
    "xminarr=[]\n",
    "yminarr=[]\n",
    "xmaxarr=[]\n",
    "ymaxarr=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.TEST.HAS_RPN = True  # Use RPN for proposals\n",
    "\n",
    "# model path\n",
    "tfmodel = os.path.join('../output', 'res152', DATASETS['coco'][0], 'default',\n",
    "                          NETS['res152'][0])\n",
    "if not os.path.isfile(tfmodel + '.meta'):\n",
    "    raise IOError(('{:s} not found.\\nDid you download the proper networks from '\n",
    "                   'our server and place them properly?').format(tfmodel + '.meta'))\n",
    "\n",
    "# set config\n",
    "tfconfig = tf.ConfigProto(allow_soft_placement=True)\n",
    "tfconfig.gpu_options.allow_growth=True\n",
    "\n",
    "# init session\n",
    "sess = tf.Session(config=tfconfig)\n",
    "net = resnetv1(num_layers=152)\n",
    "net.create_architecture(\"TEST\", 81,\n",
    "                      tag='default', anchor_scales=[2,4,8, 16, 32])\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, tfmodel)\n",
    "print('Loaded network {:s}'.format(tfmodel))\n",
    "\n",
    "def detect(sess,net,im)\n",
    "    scores, boxes = im_detect(sess, net, im)\n",
    "    cls_boxes = boxes[:, [5,4,7,6]]\n",
    "    cls_scores = scores[:, 1]\n",
    "    return cls_boxes, cls_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nozero_mean(matrix):\n",
    "    return np.sum(matrix)/(np.sum(matrix!=0.0)+1)\n",
    "\n",
    "def op_argument(det, flow, img_height, img_width):\n",
    "    #ymin xmin ymax xmax\n",
    "    dets = det.copy()\n",
    "    flow[flow<0.5] = 0.0   \n",
    "    for row,det in enumerate(dets):\n",
    "        ymin,xmin,ymax,xmax,score = det\n",
    "        deltaX = nozero_mean(flow[int(ymin):int(ymax),int(xmin):int(xmax),0])\n",
    "        deltaY = nozero_mean(flow[int(ymin):int(ymax),int(xmin):int(xmax),1])\n",
    "        det = [np.clip(ymin+deltaY,0,img_height),\\\n",
    "               np.clip(xmin+deltaX,0,img_width), \\\n",
    "               np.clip(ymax+deltaY,0,img_height),\\\n",
    "               np.clip(xmax+deltaX,0,img_width), score*0.95]\n",
    "        dets[row] = det\n",
    "    return dets\n",
    "\n",
    "for i in tqdm(range(FileLength)):\n",
    "    \n",
    "    [vid_name, img_name_mid] = lines[i].split(\"\\t\")[0].split(\"/\")\n",
    "    img_id_mid = int(img_name_mid.split(\".\")[0])\n",
    "    \n",
    "    img_ids = [img_id_mid-2, img_id_mid-1, img_id_mid+1, img_id_mid+2]\n",
    "    img_names = [\"%s/%05d.jpg\"%(vid_name,img_id) for img_id in img_ids]\n",
    "    \n",
    "    filename_mid = os.path.join(image_dir, vid_name, img_name_mid)\n",
    "    image_mid = skimage.io.imread(filename_mid)\n",
    "    boxes, scores = detect(sess,net,image_mid)\n",
    "    dets = np.hstack((boxes, scores[:, np.newaxis])).astype(np.float32)\n",
    "    \n",
    "    for img_name in img_names:\n",
    "        \n",
    "        filename = os.path.join(image_dir, img_name)\n",
    "        if os.path.exists(filename):\n",
    "            image = skimage.io.imread(filename)\n",
    "            [img_height, img_width,_] = image.shape\n",
    "            boxes, scores = detect(sess,net,image)\n",
    "            dets_ = np.hstack((boxes,scores[:, np.newaxis])).astype(np.float32)\n",
    "            prvs = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            next = cv2.cvtColor(image_mid,cv2.COLOR_BGR2GRAY)\n",
    "            opflow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            \n",
    "            dets = np.vstack((dets, op_argument(dets_, opflow, img_height, img_width)))\n",
    "    \n",
    "    detections = dets\n",
    "    print(detections)\n",
    "        \n",
    "#     Parse the outputs.\n",
    "    det_conf = detections[:,4]\n",
    "    det_xmin = detections[:,1]\n",
    "    det_ymin = detections[:,0]\n",
    "    det_xmax = detections[:,3]\n",
    "    det_ymax = detections[:,2]\n",
    "\n",
    "    top_indices1 = [m for m, conf in enumerate(det_conf) if conf > 0.1]\n",
    "    top_indices3 = [m for m, height in enumerate(det_ymax-det_ymin) if height > 0.1*img_height]\n",
    "    \n",
    "    top_indices = list(set(top_indices1) & set(top_indices3))\n",
    "    \n",
    "    top_conf = det_conf[top_indices]\n",
    "    top_xmin = det_xmin[top_indices]\n",
    "    top_ymin = det_ymin[top_indices]\n",
    "    top_xmax = det_xmax[top_indices]\n",
    "    top_ymax = det_ymax[top_indices]\n",
    "\n",
    "    if(top_conf.shape[0]!=0):\n",
    "        index_file.write(\"{} {} \".format(os.path.join(vid_name,img_name_mid),num_boxes+1))\n",
    "    for k in range(top_conf.shape[0]):\n",
    "        \n",
    "        xmin = int(round(top_xmin[k]))\n",
    "        ymin = int(round(top_ymin[k]))\n",
    "        xmax = int(round(top_xmax[k]))\n",
    "        ymax = int(round(top_ymax[k]))\n",
    "        score = top_conf[k]\n",
    "        \n",
    "#         print(image.shape[0], image.shape[1])\n",
    "#         print(xmin, xmax, ymin, ymax, score)\n",
    "        if xmin>=xmax or ymin>=ymax or xmax>image.shape[1] or ymax>image.shape[0]:\n",
    "            print('error '+p_name)\n",
    "            \n",
    "        xminarr.append(xmin);\n",
    "        yminarr.append(ymin);\n",
    "        xmaxarr.append(xmax);\n",
    "        ymaxarr.append(ymax);\n",
    "        \n",
    "        results.write(\"{}\\n\".format(os.path.join(vid_name,img_name_mid)))\n",
    "        score_file.write(\"{}\\n\".format(score))\n",
    "\n",
    "        num_boxes += 1\n",
    "    \n",
    "    if(top_conf.shape[0]!=0):\n",
    "        index_file.write(\"{}\\n\".format(num_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Boxes per image:\", float(num_boxes)/FileLength)\n",
    "results.close()    \n",
    "score_file.close()\n",
    "index_file.close()\n",
    "with h5py.File(directory+'test-bbox.h5', 'w') as hf:\n",
    "                hf.create_dataset('xmin', data=np.array(xminarr))\n",
    "                hf.create_dataset('ymin', data=np.array(yminarr))\n",
    "                hf.create_dataset('xmax', data=np.array(xmaxarr))\n",
    "                hf.create_dataset('ymax', data=np.array(ymaxarr))\n",
    "print(\"Done\")\n",
    "\n",
    "print(num_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Average Boxes per image: 9.33790179078484\n",
    "Done\n",
    "246642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/home/yuliang/code/PoseFlow/dataset/bonn-small-all.h5','r') as f:\n",
    "#     id = 2\n",
    "#     print(f['bndbox'][id])\n",
    "#     print(f['part'][id])\n",
    "#     imgname = \"\".join([chr(int(c)) for c in f['imgname'][id]])\n",
    "#     fullpath = os.path.join(root_dir, imgname)\n",
    "#     print(cv.imread(fullpath).shape)\n",
    "#     print(fullpath)\n",
    "    print('Total bndbox: ',len(f['bndbox']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
